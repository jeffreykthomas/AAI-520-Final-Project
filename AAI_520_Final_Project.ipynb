{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W2vuXhuxVZ2G","executionInfo":{"status":"ok","timestamp":1695662078901,"user_tz":600,"elapsed":19974,"user":{"displayName":"Jeffrey Thomas","userId":"00428686483222286344"}},"outputId":"f922773e-d72e-4e1f-895b-c391c5d6951d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/Shareddrives/AAI520-Final-Project/\n","!git branch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rQDnFZHEWyNw","executionInfo":{"status":"ok","timestamp":1695663446429,"user_tz":600,"elapsed":224,"user":{"displayName":"Jeffrey Thomas","userId":"00428686483222286344"}},"outputId":"05b23756-d67b-4227-d434-803819382379"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/AAI520-Final-Project\n","* \u001b[32mmaster\u001b[m\n"]}]},{"cell_type":"code","source":["import os\n","from getpass import getpass\n","\n","# Set Variables\n","username = \"jeffreykthomas\"\n","email_address = \"jeffreykthomas@gmail.com\"\n","\n","# uncomment your personal info\n","# username = \"mattwsexton\"\n","# email_address = \"\"\n","# username = \"\"\n","# email_address = \"\"\n","\n","commit_message = \"Initial Commit\"\n","repo = \"AAI-520-Final-Project\"\n","\n","# Get GitHub Token\n","token = getpass('Enter your GitHub token: ')\n","\n","# Get GitHub Token\n","token = getpass('Enter your GitHub token: ')\n","\n","# Set Git Config\n","os.system(f\"git config --global user.email {email_address}\")\n","os.system(f\"git config --global user.name {username}\")\n","\n","# Check if remote exists and Add/Update Remote accordingly\n","remote_check = !git remote | grep origin\n","if \"origin\" in remote_check:\n","    os.system(f\"git remote set-url origin https://{username}:{token}@github.com/{username}/{repo}.git\")\n","else:\n","    os.system(f\"git remote add origin https://{username}:{token}@github.com/{username}/{repo}.git\")\n","\n","# Git Add, Commit\n","os.system(f'git add \"/content/drive/Shareddrives/AAI520-Final-Project/AAI_520_Final_Project.ipynb\"')\n","os.system(f\"git commit -m '{commit_message}'\")\n","\n","# Push to the remote\n","os.system(f\"git push -u origin main\")"],"metadata":{"id":"3iaOr2e2RlZ5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695663477562,"user_tz":600,"elapsed":2026,"user":{"displayName":"Jeffrey Thomas","userId":"00428686483222286344"}},"outputId":"33e1b282-c068-4e5b-afbd-a29535fd9e78"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter your GitHub token: ··········\n","remote: Invalid username or password.\n","fatal: Authentication failed for 'https://github.com/jeffreykthomas/AAI-520-Final-Project.git/'\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uzJwkEf7f45V"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","import nltk\n","from transformers import AutoTokenizer\n","from transformers import GPT2Config, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments"]},{"cell_type":"code","source":["datafiles = 'data/TDB'\n","filename = ''"],"metadata":{"id":"C8i8jIetnNhe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initial data exploration\n","dialogue_df = pd.read_csv(filename)"],"metadata":{"id":"YQJywa8bnQeN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Some example code that will need to be adjusted based on the dataset and model we choose"],"metadata":{"id":"4MohkHjBpKVQ"}},{"cell_type":"code","source":["# Clean the text data\n","def clean_text(text):\n","    # Replace URLs with a placeholder\n","    text = re.sub(r'http\\S+', 'URL', text)\n","    # Replace numbers with a placeholder\n","    text = re.sub(r'\\d+', 'NUM', text)\n","    # Remove special characters and unnecessary whitespace\n","    text = re.sub(r'[^\\w\\s]', '', text)\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    return text"],"metadata":{"id":"AhJXMSctnb5Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('gpt-2')  # or any other model that we choose\n","\n","# Tokenize the text data\n","dialogue_df['tokens'] = dialogue_df['text'].apply(lambda x: tokenizer.tokenize(x))"],"metadata":{"id":"uBLRgHLEoYuG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Construct training examples (e.g., next sentence prediction)\n","dialogue_df['input_text'] = dialogue_df.groupby('dialogueID')['text'].transform(lambda x: ' [SEP] '.join(x))\n","dialogue_df = dialogue_df.drop_duplicates('dialogueID')\n","\n","# Split the dataset\n","train_df, test_df = train_test_split(dialogue_df, test_size=0.2, random_state=42)\n","val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42)"],"metadata":{"id":"BZlmE8l-okT5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the processed datasets\n","train_df.to_csv('data/train.csv', index=False)\n","val_df.to_csv('data/val.csv', index=False)\n","test_df.to_csv('data/test.csv', index=False)"],"metadata":{"id":"hgjs81_mopp9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the datasets\n","train_dataset = TextDataset(\n","   tokenizer=tokenizer,\n","   file_path=\"data/train.csv\",\n","   block_size=128,\n",")\n","eval_dataset = TextDataset(\n","   tokenizer=tokenizer,\n","   file_path=\"data/val.csv\",\n","   block_size=128,\n",")\n","\n","# Define data collator\n","data_collator = DataCollatorForLanguageModeling(\n","   tokenizer=tokenizer,\n","   mlm=False,\n",")\n","\n","# Initialize model configuration\n","configuration = GPT2Config.from_pretrained('gpt-2')  # or the other model we choose\n","model = GPT2LMHeadModel(configuration)\n","\n","# Setup training arguments\n","training_args = TrainingArguments(\n","   output_dir=\"model/output\",\n","   overwrite_output_dir=True,\n","   num_train_epochs=3,\n","   per_device_train_batch_size=4,\n","   save_steps=10_000,\n","   save_total_limit=1,\n",")\n","\n","# Initialize Trainer\n","trainer = Trainer(\n","   model=model,\n","   args=training_args,\n","   data_collator=data_collator,\n","   train_dataset=train_dataset,\n","   eval_dataset=eval_dataset,\n",")\n","\n","# Train the model\n","trainer.train()\n","trainer.save_model(\"model/output\")"],"metadata":{"id":"Amh0rN9Qow7c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"p-YpqS3QSoSD"},"execution_count":null,"outputs":[]}]}